## 가상 메모리(Virtual Memory System)의 필요성

- 리눅스에서는 하나의 프로세스가 4GB이다. (커널 1GB,사용자 메모리 3GB)
- 그러나 통상 물리 메모리 크기는 8GB ~ 16GB, 즉 여러 프로세스를 물리 메모리에 적재하는 데에 한계가 존재함.
- 여러 프로세스가 동시 실행되는 멀티 프로그래밍 시스템에서의 메모리 용량 부족 이슈와 프로세스 메모리 영역간 침범이슈를 해결하고자 가상메모리 기술이 등장

## 가상 메모리란 ?

- 메모리가 실제 메모리 보다 많아보이게 하는 기술이다.
  - 실제 메모리에서 사용되는 영역은 적다는 점에 착안하여 고안된 기술이다.
  - 프로세스간 공간 분리로 프로세스이슈가 전체 시스템에 영향을 주지 않는다.

## 가상 메모리의 아이디어

- 프로세스는 가상 주소를 사용하고, 해당 가상 주소에 데이터를 읽고 쓸때만, 물리주소로 변환해 준다.
- 가상 주소 : 프로세스가 참조하는 주소
- 물리 주소 : 실제 메모리 주소

> MMU(Memory Management Unit)
> - CPU에 코드 실행시, 가상 주소 메모리 접근이 필요할때, 해당 주소를 물리주소값으로 변환해주는 장치
> - 하드웨어 장치를 이용해야 주소 변환이 빠르기 때문에 별도의 장치(MMU)를 둠
> ![image](https://user-images.githubusercontent.com/49670068/119520690-784d6380-bdb5-11eb-8902-86bb8944e06b.png)

## 페이징 시스템

- 프로세스를 페이지단위로 쪼개어 가상 주소 공간과 물리 주소 공간을 관리한다.
- 하드웨어 지원이 필요하다.
- 리눅스에서는 페이지가 4KB단위이다.
- 페이지 번호를 기반으로 가상주소와 물리주소 매핑정보를 기록,사용한다.

> 페이지 : 고정된 크기의 BLOCK(4KB)

## 페이징 시스템의 구조와 원리

- 프로세스(4GB)의 PCB에 PAGE 테이블 구조체를 가르키는 주소가 들어있다.
- PAGE 테이블 : 가상주소와 물리주소간의 매핑 정보 테이블
- V(가상 주소) = (P,D)
    - P: 페이지 번호
    - D : 변위(오프셋)
![image](https://user-images.githubusercontent.com/49670068/119522004-98c9ed80-bdb6-11eb-8619-70eb06fa0306.png)


- 페이지 크기가 4KB라면 0~11비트가 변위 12비트 이상이 페이지 번호를 나타낸다.

> 프로세스가 4GB를 사용하는 이유
> - 32BIT 운영체제에서는 표현가능한 주소의 개수(주소당 1BYTE)가 2의 32승(4GB)이다.

## 페이지 테이블

- 페이지번호와 해당 페이지의 첫 물리주소 정보를 매핑한 표이다.

![image](https://user-images.githubusercontent.com/49670068/119523941-26f2a380-bdb8-11eb-89e7-a3e8aba2a584.png)

- 위 그림을 보시게 되면 aspect라는 코드는 page 3번에 변위가 2라는 가상주소를 가지고 있습니다.
- 페이징 테이블에서 page 3번의 물리주소는 1000h이고, 변위값만큼을 더한 실제 물리메모리상의 참조주소는 1002h가 됩니다.

> 프로세스 생성시, 페이지 테이블 정보가 생성됩니다.
> - PCB에서 페이지 테이블 접근이 가능하며, 관련정보는 물리메모리에 적재됩니다.
> - 프로세스 구동시 해당 페이지 테이블 BASE주소가 별도 레지스터(CR3)에 저장됩니다.
> - CPU가 가상주소 접근시 MMU가 페이지 테이블 BASE 주소에 접근하여 물리주소를 가져옵니다.

## 다중 단계 페이징 시스템

- 32bit 시스템에서 페이징 시스템은 가상주소 중 상위 20bit를 페이징 번호로 사용한다.
- 즉, 2의 20승(1048576)개의 페이지 정보가 필요하며, 매번 프로세스 생성시 페이지 정보가 많이 사용되지도 않는데, 2의 20승 페이지 정보에 해당하는 페이징 테이블을 만든다면 공간이 낭비될 수 있다.
- 그래서 페이징 테이블을 페이지 디렉토리라는 단위로 한번더 나누어 페이지를 관리하는 다중 단계 페이징 시스템이 등장했다.

![image](https://user-images.githubusercontent.com/49670068/119525448-78e7f900-bdb9-11eb-82b6-43822f4c15a1.png)

## TLB(Translation Lookaside Buffer) : 페이지 정보 캐시

- MMU는 페이지 번호에 해당하는 물리주소를 확인하기 위해 물리 메모리를 매번 갔다와야한다.
- 이러한 과정으로 인한 시간소요를 줄이기위해 TLB라는 캐시를 둔다.
- TLB는 이미 요청한 페이지 번호에 대한 물리주소를 저장하는 버퍼공간이다.
- TLB에 CPU에서 필요로하는 페이지번호에대한 물리주소를 가지고 있다면 물리주소 데이터를 가져오는 단계를 줄일 수 있다.

![image](https://user-images.githubusercontent.com/49670068/119526634-86ea4980-bdba-11eb-8651-795afbfb4da0.png)

## 페이징 시스템과 공유 메모리

- FORK를 통해 자식 프로세스(부모 복제)를 생성한 경우, 공간절약을 위해 동일한 물리 메모리 공간을 참조할 수 있다.(공간절약 , 메모리 할당시간 절약)

![image](https://user-images.githubusercontent.com/49670068/119526944-ce70d580-bdba-11eb-8a30-6c75905b49bd.png)

- 물리주소에 데이터 수정시도시 비로소 물리 메모리 공간이 복사된다.
- 예를 들어 자식 프로세스 데이터 수정시도시, 물리 메모리에서 기존 공간이 복사되고, 자식 프로세스의 페이징 테이블을 갱신한다.

![image](https://user-images.githubusercontent.com/49670068/119527291-24de1400-bdbb-11eb-9e5a-2ba8e6f7fee0.png)

## 요구 페이징

- 프로세스 모든 데이터를 메모리로 적재하지 않고, 실행 중 필요한 영역만 해당 시점에 물리메모리에 적재
    - 선행 페이징(미리 프로세스 관련 모든 데이터를 메모리에 적재)의 반대되는 개념
    - 더 이상 필요하지 않은 페이지 프레임은 다시 저장매체(SSD,HDD)에 저장한다.

## 페이지 폴트와 인터럽트

- 요청한 페이지가 실제 물리 메모리에 없을 때, 일어나는 인터럽트이다.
- 페이지 폴트가 일어나면 해당 페이지를 물리메모리에 올린다.

![image](https://user-images.githubusercontent.com/49670068/119527716-8dc58c00-bdbb-11eb-999a-953590a38f97.png)

1. cpu에서 가상 주소를 mmu에 요청한다.
2. cr3 레지스터에 있는 값(페이지 테이블 base주소)을 참조하여 물리메모리에 접근
3. 요청하는 페이지가 물리메모리에 없다면 페이지 폴트 인터럽트 발생
4. 운영체제는 페이지 폴트 발생시 저장매체로 부터 요청한 페이지를 찾는다.
5. 저장매체로부터 해당 페이지를 물리메모리에 적재
6. 페이징 테이블에 물리메모리 주소 갱신

## 페이지 교체 정책

- OS가 특정 페이지를 물리 메모리에 올리려 하는데, 물리메모리가 꽉찼다면 ??
    - 기존 페이지 중 하나를 물리메모리에서 저장 매체로 내리고,
    - 새로운 페이지를 물리 메모리공간에 올려야한다.
- 이때, 어떠한 페이지를 내릴 것인가 ? (페이지 알고리즘이 존재한다.) 

1. FIFO

- 가장 먼저 들어온 페이지를 내린다.

![image](https://user-images.githubusercontent.com/49670068/119531062-8b186600-bdbe-11eb-9f55-9979ec2f75d6.png)

2. OPT(Optimal Relacement Algorithm)

- 앞으로 가장 오랫동안 사용하지 않을 페이지를 내린다.
- 예측해야하는데, 일반 OS에서는 구현이 불가하다.

![image](https://user-images.githubusercontent.com/49670068/119531403-d6cb0f80-bdbe-11eb-956f-b97a42006c7e.png)

3. LRU(Least Recently Used)

- 가장 오래전에 사용된 페이지를 교체한다.(사용한지 가장 오래된 페이지)
- opt 알고리즘은 구현이 불가하므로, 과거기록을 기반으로 시도하는 방법이다.

![image](https://user-images.githubusercontent.com/49670068/119531630-1560ca00-bdbf-11eb-9b23-2ab9bc952b3f.png)

> LRU는 메모리 지역성이라고 특징을 이용해 만든 알고리즘이다.
> 메모리 지역성이란, 프로세스가 근접한 메모리공간을 연속하여 참조하는 특징이다.
> 즉, 최근에 사용된 페이지는 다시 참조할 가능성이 크니, 사용한지 오래된 페이지를 교체하는 것이 효율적이다.

4. LFU(Least Frequently Used)

- 가장 적게 사용된 페이지를 내린다.

![image](https://user-images.githubusercontent.com/49670068/119531809-417c4b00-bdbf-11eb-85b6-b9d2895a48ad.png)


5. NRU(Not Used Recently)

- LRU와 마찬가지로 최근에 사용하지 않은 페이지부터 교체한다. 다만 메모리에 대한 읽기와 쓰기비트를 기반으로 한다.
- 각 페이지마다 (READ,MODIFY) 비트를 두고 (0,0),(0,1),(1,0),(1,1)순으로 페이지를 교체한다.
- 즉, 읽기 쓰기가 둘다 진행된 페이지일 수록 교체될 가능성이 낮다. 

![image](https://user-images.githubusercontent.com/49670068/119532309-b94a7580-bdbf-11eb-8664-890ad8b7df08.png)


> 프로그램을 너무 많이 띄우면 프로그램 전환시 빈번한 페이지 교체 작업으로 인해 버벅인다.

> 스레싱(Trashing) 이란?
> - 과도하게 페이지 폴트가 발생하여 실제로는 아무일도 하지 못하는 상황

## 세그멘테이션 기법

- 페이징 기법과 달리 가상메모리를 서로 크기가 다른 논리적 단위인 세그먼트로 분할한다.
    - 페이징 기법에서는 페이지라는 4KB의 동일한 크기의 블록으로 분할
    - 예로 x86 리얼모드에서는 CS(CODE 세그먼트),DS(DATA 세그먼트),SS(STACK 세그먼트),ES(EXTRA 세그먼트) 세그먼트로 나눈다.

- 세그먼트 가상주소
    - V(가상주소) = (S,D) : S는 세그먼트 번호, D는 변위

![image](https://user-images.githubusercontent.com/49670068/119532760-23631a80-bdc0-11eb-9247-33ba7ccad2dd.png)

- 세그멘테이션은 크기가 다른 세그먼트로 물리메모리에 적재된다.

![image](https://user-images.githubusercontent.com/49670068/119532875-3ece2580-bdc0-11eb-9b39-bdd7c54251c7.png)

> 내부 단편화(페이지 기법에서 발생)
> - 페이지는 4KB단위인데 실제 사용되는 영역이 정확히 4KB로 나누어 떨어지진 않는다.
> - 페이지 블록만큼 데이터가 딱 맞게 채워져 있지 않을때 공간 낭비가 발생(4KB단위로 나누어지는데 3KB가 공란인 경우)

> 외부 단편화(세그멘테이션 기법)
> - 물리메모리가 원하는 연속된 크기의 메모리를 제공해주지 못할때 발생
> - 가변크기로 인해 물리메모리에 외부 단편화가 발생할 수 있다.

> 세그멘테이션과 페이징 기법 모든 하드웨어 지원이 필요하다. 이식성을 중요시하는 리눅스는 페이징 기법을 기반으로 구현되어 있다.(INTEL,ARM과 같이 다양한 CPU들은 대부분 페이징 기법은 제공하나 세그먼테이션을 제공하지 않는 경우가 많음)